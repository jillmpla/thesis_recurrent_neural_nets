{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard via command-line\n",
    "#tensorboard --logdir=/full_path_to_your_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "#What is the maximum flare class produced by an AR in the next 24hrs after a 24hr time sequence?\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "#feature data from - hmi.sharp_720s:::\n",
    "#http://jsoc.stanford.edu/doc/data/hmi/sharp/sharp.htm\n",
    "\n",
    "#label data from - GOES flare events:::\n",
    "#ftp://ftp.swpc.noaa.gov/pub/warehouse/\n",
    "\n",
    "#and from - GOES XRS Report:::\n",
    "#https://www.ngdc.noaa.gov/stp/space-weather/solar-data/solar-features/solar-flares/x-rays/goes/xrs/\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "#binary class - F for flare and N for no flare\n",
    "#multi-class - #6 flare classes: N is no flare, A is smallest, X is largest\n",
    "               #key = {'N', 'A', 'B', 'C', 'M', 'X'}\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"tensorflow version:\", tf.__version__) #2.3.1 used\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "from astropy.time import Time\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Dropout, Dense, Embedding, Flatten, SimpleRNN, LSTM, GRU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import drms #https://pypi.org/project/drms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Flare_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################creates/loads csv with 2012's feature data##########\n",
    "current_di = os.getcwd()\n",
    "csv_for_2012 = \"\\\\create_2012_features.csv\"\n",
    "where_2012 = current_di + csv_for_2012\n",
    "\n",
    "if not os.path.exists(where_2012):\n",
    "    import to_create_2012\n",
    "    to_create_2012.get_2012_Features()\n",
    "    df_2012 = pd.read_csv('create_2012_features.csv', index_col=0)\n",
    "    df_2012_done = Flare_Data.convert_time_2012(df_2012)\n",
    "    Flare_Data.save_some_features(df_2012_done) \n",
    "\n",
    "if os.path.exists(where_2012):\n",
    "    df_2012 = pd.read_csv('create_2012_features.csv', index_col=0)\n",
    "    df_2012_done = Flare_Data.convert_time_2012(df_2012)\n",
    "    Flare_Data.save_some_features(df_2012_done)\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################creates/loads csv with 2013's feature data##########\n",
    "current_di = os.getcwd()\n",
    "csv_for_2013 = \"\\\\create_2013_features.csv\"\n",
    "where_2013 = current_di + csv_for_2013\n",
    "\n",
    "if not os.path.exists(where_2013):\n",
    "    import to_create_2013\n",
    "    to_create_2013.get_2013_Features()\n",
    "    df_2013 = pd.read_csv('create_2013_features.csv', index_col=0)\n",
    "    df_2013_done = Flare_Data.convert_time_2013(df_2013)\n",
    "    Flare_Data.save_some_features(df_2013_done) \n",
    "\n",
    "if os.path.exists(where_2013):\n",
    "    df_2013 = pd.read_csv('create_2013_features.csv', index_col=0)\n",
    "    df_2013_done = Flare_Data.convert_time_2013(df_2013)\n",
    "    Flare_Data.save_some_features(df_2013_done)\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################creates/loads csv with 2014's feature data##########\n",
    "current_di = os.getcwd()\n",
    "csv_for_2014 = \"\\\\create_2014_features.csv\"\n",
    "where_2014 = current_di + csv_for_2014\n",
    "\n",
    "if not os.path.exists(where_2014):\n",
    "    import to_create_2014\n",
    "    to_create_2014.get_2014_Features()\n",
    "    df_2014 = pd.read_csv('create_2014_features.csv', index_col=0)\n",
    "    df_2014_done = Flare_Data.convert_time_2014(df_2014)\n",
    "    Flare_Data.save_some_features(df_2014_done) \n",
    "\n",
    "if os.path.exists(where_2014):\n",
    "    df_2014 = pd.read_csv('create_2014_features.csv', index_col=0)\n",
    "    df_2014_done = Flare_Data.convert_time_2014(df_2014)\n",
    "    Flare_Data.save_some_features(df_2014_done)\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################creates/loads csv with 2015's feature data##########\n",
    "current_di = os.getcwd()\n",
    "csv_for_2015 = \"\\\\create_2015_features.csv\"\n",
    "where_2015 = current_di + csv_for_2015\n",
    "\n",
    "if not os.path.exists(where_2015):\n",
    "    import to_create_2015\n",
    "    to_create_2015.get_2015_Features()\n",
    "    df_2015 = pd.read_csv('create_2015_features.csv', index_col=0)\n",
    "    df_2015_done = Flare_Data.convert_time_2015(df_2015)\n",
    "    Flare_Data.save_some_features(df_2015_done) \n",
    "\n",
    "if os.path.exists(where_2015):\n",
    "    df_2015 = pd.read_csv('create_2015_features.csv', index_col=0)\n",
    "    df_2015_done = Flare_Data.convert_time_2015(df_2015)\n",
    "    Flare_Data.save_some_features(df_2015_done)\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ipython().run_line_magic('load_ext', 'tensorboard')\n",
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes old tensorboard Logs and recreates or creates Logs folder\n",
    "current_dir = os.getcwd()\n",
    "l_folder = \"\\\\Logs\"\n",
    "where_logs = current_dir + l_folder\n",
    "\n",
    "if not os.path.exists(where_logs):\n",
    "    os.mkdir(where_logs)\n",
    "    \n",
    "if os.path.exists(where_logs):\n",
    "    shutil.rmtree(where_logs)\n",
    "    os.mkdir(where_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary = True for binary classification, binary = False for multi-class classification\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, tim_steps, n_feats, count_of_classes = Flare_Data.getAllData(binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~[LSTM_1 Model]~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(tim_steps, n_feats)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(count_of_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_cb = keras.callbacks.TensorBoard(\n",
    "    log_dir=where_logs,\n",
    "    histogram_freq=0,  # how often to log histogram visualizations\n",
    "    embeddings_freq=1,  # how often to log embedding visualizations\n",
    "    update_freq=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=(X_val, y_val), \n",
    "          callbacks=[tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model on test set\n",
    "results = model.evaluate(X_test, y_test, batch_size=1)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate predictions for 3\n",
    "predictions = model.predict(X_test[:3])\n",
    "print(\"predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test.argmax(axis=1), predicted_flare_class.argmax(axis=1))\n",
    "print(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
